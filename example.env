# MongoDB Configuration
MONGODB_URI=mongodb://admin:password@localhost:27017/california_procurement?authSource=admin
MONGODB_DB=california_procurement
MONGODB_COLLECTION=purchase_orders

# Primary LLM Configuration (generic, defaults to Grok-style values)
PRIMARY_LLM_API_KEY=
PRIMARY_LLM_MODEL=grok-4-1-fast-non-reasoning
PRIMARY_LLM_TEMPERATURE=0.1
PRIMARY_LLM_BASE_URL=https://api.x.ai/v1

# LangSmith / LangChain observability (optional)
LANGCHAIN_TRACING_V2=false
LANGCHAIN_API_KEY=
LANGCHAIN_PROJECT=procurement-agent-debug
LANGCHAIN_ENDPOINT=https://api.smith.langchain.com

# Reference documentation vector store
REFERENCE_DOCS_DIR=data
VECTOR_STORE_DIR=data/reference_index
VECTOR_COLLECTION_NAME=procurement_reference
EMBEDDING_MODEL_NAME=sentence-transformers/all-MiniLM-L6-v2
EMBEDDING_DEVICE=cpu
REFERENCE_CHUNK_SIZE=1000
REFERENCE_CHUNK_OVERLAP=150

# DSPy Configuration (for improved query generation)
LLM_PROVIDER=grok  # Options: openai, grok, anthropic, google
USE_DSPY_FOR_QUERIES=false  # Set to true to use DSPy instead of raw prompt engineering
DSPY_MODEL_CACHE_DIR=data/dspy_cache
DSPY_COMPILE_ON_STARTUP=false
DSPY_TRAINING_DATA_PATH=data/dspy_training_data.json
DSPY_OPTIMIZED_MODEL_PATH=models/dspy_optimized


